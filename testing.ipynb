{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10f9932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the data\n",
    "outfit_df = pickle.load(open('outfit_df.pkl', 'rb'))\n",
    "jewelry_df = pickle.load(open('jewelry_df.pkl', 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48df8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend jewelry based on features\n",
    "def recommend_jewelry(features, feature_list):\n",
    "    neighbors = NearestNeighbors(n_neighbors=10, algorithm='brute', metric='euclidean')\n",
    "    neighbors.fit(feature_list)\n",
    "    distances, indices = neighbors.kneighbors([features])\n",
    "    filtered_indices = indices[0]\n",
    "    return filtered_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2f21a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend similar items\n",
    "def recommend_similar_items(features):\n",
    "    neighbors = NearestNeighbors(n_neighbors=10, algorithm='brute', metric='euclidean')\n",
    "    neighbors.fit(outfit_df['features'].tolist())\n",
    "    distances, indices = neighbors.kneighbors([features])\n",
    "    return indices[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ade59416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from an image using ResNet50\n",
    "def extract_features(img_path):\n",
    "    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    features = model.predict(img_data)\n",
    "    return features[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14dee6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Recall@K\n",
    "def recall_at_k(recommended_indices, relevant_indices, k):\n",
    "    recommended_k = recommended_indices[:k]\n",
    "    relevant_set = set(relevant_indices)\n",
    "    recommended_set = set(recommended_k)\n",
    "    intersection = recommended_set.intersection(relevant_set)\n",
    "    recall = len(intersection) / len(relevant_set) if relevant_set else 0.0\n",
    "    return recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "948db0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Precision@K\n",
    "def precision_at_k(recommended_indices, relevant_indices, k):\n",
    "    recommended_k = recommended_indices[:k]\n",
    "    relevant_set = set(recommended_indices)\n",
    "    recommended_set = set(recommended_k)\n",
    "    intersection = recommended_set.intersection(relevant_set)\n",
    "    precision = len(intersection) / k if k else 0.0\n",
    "    return precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a723a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate F1@K\n",
    "def f1_at_k(recommended_indices, relevant_indices, k):\n",
    "    recall = recall_at_k(recommended_indices, relevant_indices, k)\n",
    "    precision = precision_at_k(recommended_indices, relevant_indices, k)\n",
    "    if recall + precision == 0:\n",
    "        return 0.0\n",
    "    return 2 * (recall * precision) / (recall + precision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93bdbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def accuracy_at_k(recommended_indices, relevant_indices, k):\n",
    "    recommended_k = recommended_indices[:k]\n",
    "    relevant_set = set(relevant_indices)\n",
    "    recommended_set = set(recommended_k)\n",
    "    intersection = recommended_set.intersection(relevant_set)\n",
    "    accuracy = len(intersection) / k if k else 0.0\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89d4f46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path of outfit image: \"C:\\Users\\pragy\\OneDrive\\Desktop\\ml files\\images\\22563.jpg\"\n"
     ]
    }
   ],
   "source": [
    "user_image_path = input(\"Enter the path of outfit image: \").strip()\n",
    "\n",
    "# Ensure the path is handled correctly\n",
    "user_image_path = user_image_path.replace('\"', '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c598d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Extracted Features:  [0.         0.3324459  0.02588665 ... 0.05161736 0.46936205 0.13284789]\n",
      "Enter the gender of the outfit (e.g., Men/Women): unisex\n",
      "Enter the article type of the outfit (e.g., Dresses, Lehenga Choli, Salwar and Dupatta, Sarees, Kurta Sets): bag\n",
      "No matching outfits found for the given gender and article type.\n",
      "Recommending similar items based on outfit features...\n",
      "Predicted Similar Indices: [ 2544  4210 25341  9527 33920]\n",
      "Predicted Similar IDs: [22563, 22562, 22561, 25430, 18796]\n",
      "Enter the accurate indices separated by commas (e.g., 1,2,3,4,5): 22563,22562,22561,25430,22565\n",
      "Recall@5: 0.8\n",
      "Precision@5: 1.0\n",
      "F1@5: 0.888888888888889\n",
      "Accuracy@5: 0.8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    query_features = extract_features(user_image_path)\n",
    "    \n",
    "    # Print extracted features for debugging\n",
    "    print(\"Extracted Features: \", query_features)\n",
    "    \n",
    "    # Ask the user for additional information\n",
    "    gender = input(\"Enter the gender of the outfit (e.g., Men/Women): \").capitalize()\n",
    "    article_type = input(\"Enter the article type of the outfit (e.g., Dresses, Lehenga Choli, Salwar and Dupatta, Sarees, Kurta Sets): \").title()\n",
    "    \n",
    "    is_womens_outfit = (gender == 'Women')\n",
    "    is_apparel = (article_type in ['Dresses', 'Lehenga Choli', 'Salwar and Dupatta', 'Sarees', 'Kurta Sets'])\n",
    "    \n",
    "    # Filter the dataset based on the provided gender and articleType\n",
    "    filtered_outfit_df = outfit_df[(outfit_df['gender'] == gender) & (outfit_df['articleType'] == article_type)]\n",
    "    \n",
    "    if not filtered_outfit_df.empty:\n",
    "        filtered_indices = filtered_outfit_df.index.tolist()\n",
    "        filtered_features = filtered_outfit_df['features'].tolist()\n",
    "        \n",
    "        # Recommend jewelry based on outfit features\n",
    "        recommended_indices = recommend_jewelry(query_features, jewelry_df['features'].tolist())\n",
    "        \n",
    "        if len(recommended_indices) == 0:\n",
    "            print(\"No recommended jewelry items found.\")\n",
    "        else:\n",
    "            # Display the recommended jewelry images\n",
    "            for i in recommended_indices[:5]:  # Displaying top 5 recommendations\n",
    "                temp_img = cv2.imread(jewelry_df.loc[i, 'productImage'])\n",
    "                cv2.imshow('Recommended Jewelry', cv2.resize(temp_img, (512, 512)))\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "    else:\n",
    "        print(\"No matching outfits found for the given gender and article type.\")\n",
    "        print(\"Recommending similar items based on outfit features...\")\n",
    "        \n",
    "        # Recommend similar items based on outfit features\n",
    "        similar_indices = recommend_similar_items(query_features)\n",
    "        \n",
    "        if len(similar_indices) == 0:\n",
    "            print(\"No similar items found.\")\n",
    "        else:\n",
    "            # Display the recommended similar outfit images\n",
    "            for i in similar_indices[:5]:  # Displaying top 5 recommendations\n",
    "                temp_img = cv2.imread(outfit_df.loc[i, 'imagePath'])\n",
    "                cv2.imshow('Recommended Similar Outfit', cv2.resize(temp_img, (512, 512)))\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "        # Map the predicted indices to their IDs\n",
    "        predicted_ids = [outfit_df.loc[i, 'id'] for i in similar_indices[:5]]\n",
    "        print(f\"Predicted Similar Indices: {similar_indices[:5]}\")\n",
    "        print(f\"Predicted Similar IDs: {predicted_ids}\")\n",
    "    \n",
    "    # Get accurate indices from user\n",
    "    accurate_indices_input = input(\"Enter the accurate indices separated by commas (e.g., 1,2,3,4,5): \").strip()\n",
    "    accurate_indices = list(map(int, accurate_indices_input.split(',')))\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    k = 5  # Number of top recommendations to consider\n",
    "\n",
    "    # Use predicted_indices for jewelry or similar items\n",
    "    if is_womens_outfit and is_apparel:\n",
    "        predicted_ids = [jewelry_df.loc[i, 'id'] for i in recommended_indices[:5]]\n",
    "    else:\n",
    "        predicted_ids = [outfit_df.loc[i, 'id'] for i in similar_indices[:5]]\n",
    "    \n",
    "    recall = recall_at_k(predicted_ids, accurate_indices, k)\n",
    "    precision = precision_at_k(predicted_ids, accurate_indices, k)\n",
    "    f1_score = f1_at_k(predicted_ids, accurate_indices, k)\n",
    "    accuracy = accuracy_at_k(predicted_ids, accurate_indices, k)\n",
    "\n",
    "    print(f\"Recall@{k}: {recall}\")\n",
    "    print(f\"Precision@{k}: {precision}\")\n",
    "    print(f\"F1@{k}: {f1_score}\")\n",
    "    print(f\"Accuracy@{k}: {accuracy}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87382f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
